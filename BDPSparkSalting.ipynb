{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7111fc4-3f45-4ba6-a76e-e82b339c6f6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5da014a-05aa-40b3-967a-8c13d23ff4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeafdcd-86a4-41a9-a36d-384c4b583c17",
   "metadata": {},
   "source": [
    "## Initiate Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31dbf2d5-eaa8-4f58-bcc7-f5d00388ae7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "conf=SparkConf()\n",
    "conf.set(\"spark.driver.memory\",      \"2g\" ) \n",
    "conf.set(\"spark.executor.memory\",    \"2g\" )\n",
    "conf.set(\"spark.executor.instances\", \"5\"  )\n",
    "\n",
    "spark = SparkSession.builder.master(\"yarn\").appName(\"Spark Salting Example\").enableHiveSupport().config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866bafa-609f-492e-9755-570ac4368b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165f4f7d-99bf-4dd3-9aae-81d8c8f6e735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Salting Example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3c76fa1bd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e4268-8677-497f-92b2-4e44054249c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31bb3955-2482-490f-a85e-7b5d544ab0bc",
   "metadata": {},
   "source": [
    "### Table 1: Balanced Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c16a5683-7322-4a35-a6e6-f969f4385da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "dataSize=1000000\n",
    "df_balanced_part = spark.createDataFrame([i for i in range(dataSize)], IntegerType())\n",
    "df_balanced_part = df_balanced_part.withColumn(\"partitionId\", F.spark_partition_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316644a9-e2fa-4da1-a467-97bbccbd1f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:00:36 WARN scheduler.TaskSetManager: Stage 0 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_part.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb694313-1fec-4ce2-8833-e98c1274a4da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:00:42 WARN scheduler.TaskSetManager: Stage 2 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|partitionId| count|\n",
      "+-----------+------+\n",
      "|          0|199680|\n",
      "|          1|199680|\n",
      "|          2|200704|\n",
      "|          3|199680|\n",
      "|          4|200256|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_balanced_part.groupby([df_balanced_part.partitionId]).count().sort(df_balanced_part.partitionId).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea232f9-0f8d-4b85-b583-17506ad51dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:00:48 WARN scheduler.TaskSetManager: Stage 4 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "| value|partitionId|\n",
      "+------+-----------+\n",
      "|199680|          1|\n",
      "|199681|          1|\n",
      "|199682|          1|\n",
      "|199683|          1|\n",
      "|199684|          1|\n",
      "|199685|          1|\n",
      "|199686|          1|\n",
      "|199687|          1|\n",
      "|199688|          1|\n",
      "|199689|          1|\n",
      "+------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:00:49 WARN scheduler.TaskSetManager: Lost task 4.1 in stage 4.0 (TID 216) (datanode2 executor 2): TaskKilled (Finish but did not commit due to another attempt succeeded)\n"
     ]
    }
   ],
   "source": [
    "df_balanced_part.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a9d719-5ade-4995-b16c-237821cbf2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_part.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870dfae-9fac-4937-bab8-ab83c8c65671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8dfcaed-df5e-4508-9e79-339036e6a662",
   "metadata": {},
   "source": [
    "### Table 2: Unbalanced data (Skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d4c3f2-d5b5-4e4a-93e1-c963baf0839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = spark.createDataFrame([0] * (dataSize-2), IntegerType()).repartition(1)\n",
    "df1 = spark.createDataFrame([1], IntegerType()).repartition(1)\n",
    "df2 = spark.createDataFrame([2], IntegerType()).repartition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c31e3d15-51c7-4ae6-8021-5f51b00f2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skew = df0.union(df1).union(df2)\n",
    "df_skew = df_skew.withColumn(\"partitionId\", F.spark_partition_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b99c4e93-7ec2-469e-89a6-660c38bef534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=======================================>              (146 + 6) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|partitionId| count|\n",
      "+-----------+------+\n",
      "|          0|999998|\n",
      "|          1|     1|\n",
      "|          2|     1|\n",
      "+-----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_skew.groupby([df_skew.partitionId]).count().sort(df_skew.partitionId).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8b846-45c3-49ba-afe3-f6adc467b9b6",
   "metadata": {},
   "source": [
    "### Join Tables without Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9f3f59e-907f-4aae-b5eb-e677bf411e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: integer (nullable = true)\n",
      " |-- partitionId: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_skew.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5914c8fb-acd3-45f2-be35-1fcfa5ad1be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: integer (nullable = true)\n",
      " |-- partitionId: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_balanced_part.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30708cb1-8ce1-42b5-a7fd-e854a0848692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:00:54 WARN scheduler.TaskSetManager: Stage 14 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skew.join(df_balanced_part.select(\"value\"),\"value\", \"inner\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef8777-2bf1-4ffa-ac76-cc1139d790fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7615b-cb25-4f72-84eb-b5396994d836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162bff8-52f1-4b7c-97aa-af1d9ced95bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06693abf-4f83-48bd-867c-ec0ae0f092da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "826f0968-d81f-4936-9fc4-f02c47ddbcbd",
   "metadata": {},
   "source": [
    "### How to resolve the Spark data skew problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e50de5-1836-408f-b05f-5795f105dc69",
   "metadata": {},
   "source": [
    "#### 1. Leveraging the Number of Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6681582c-8ab8-44aa-8902-8a03a003a964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.shuffle.partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e990157-de80-4580-903d-3af3a5d2580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c370062d-4e40-4ed0-a333-f19c824bb225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:00:58 WARN scheduler.TaskSetManager: Stage 21 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skew.join(df_balanced_part.select(\"value\"),\"value\", \"inner\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2579ee5a-223b-40b8-9ffd-d16c4bd28fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "961f1882-912c-4666-9737-daabb0dcea2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Broadcast join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1637f677-680f-40a2-a041-53a613c6f98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:01:00 WARN scheduler.TaskSetManager: Stage 25 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/03/26 11:01:02 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 29.0 (TID 717) (datanode1 executor 5): TaskKilled (another attempt succeeded)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skew.join(F.broadcast(df_balanced_part.select(\"value\")),\"value\", \"inner\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ba28a-ea47-4543-a73b-191ca56e036f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fb542a0-4793-4e92-adfd-9b48ed30b4d8",
   "metadata": {},
   "source": [
    "## Salting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d64cc2e3-f97f-4636-9ded-596db76c576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f2429e4-37ce-4b39-bea4-1e98408d92fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numPart = spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
    "numPart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ad6f0f3-5a86-48de-bf0e-d6dab6908bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: int, partitionId: int, salt: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skew_salt = df_skew.withColumn(\"salt\", F.concat(df_skew.value, F.lit(\"_\"), F.lit( F.floor(F.rand() * numPart))))\n",
    "\n",
    "df_skew_salt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12d1fdd8-35b7-4cd7-bbdf-efc0d23af1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|partitionId| count|\n",
      "+-----------+------+\n",
      "|          0|999998|\n",
      "|          1|     1|\n",
      "|          2|     1|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_skew_salt.groupby([df_skew_salt.partitionId]).count().sort(df_skew_salt.partitionId).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "345b0655-9cac-4952-a8aa-6eb2d4c6dc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skew_salt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a80b7bb0-1f17-4694-a3c7-4cb932d4aee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+----+\n",
      "|value|partitionId|salt|\n",
      "+-----+-----------+----+\n",
      "|    0|          0| 0_2|\n",
      "|    0|          0| 0_1|\n",
      "|    0|          0| 0_2|\n",
      "|    0|          0| 0_2|\n",
      "|    0|          0| 0_0|\n",
      "+-----+-----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_skew_salt.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d5a9f2-c383-4a79-bd95-d8b2f56f1cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55a16404-3361-43a2-8ff3-2830815bf518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_salt = df_balanced_part.withColumn(\"salt_array\", F.array([F.lit(i) for i in range(int(numPart))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ffcbcbe-be0c-4ca7-b9af-019e36e75b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+----------+\n",
      "|value|partitionId|salt_array|\n",
      "+-----+-----------+----------+\n",
      "|0    |0          |[0, 1, 2] |\n",
      "|1    |0          |[0, 1, 2] |\n",
      "|2    |0          |[0, 1, 2] |\n",
      "|3    |0          |[0, 1, 2] |\n",
      "|4    |0          |[0, 1, 2] |\n",
      "+-----+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:01:04 WARN scheduler.TaskSetManager: Stage 45 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "df_balanced_salt.show(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "520c2826-732b-4693-a25e-70eada995915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:01:04 WARN scheduler.TaskSetManager: Stage 46 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_salt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9d3f7c2-5c88-441d-b9db-1935bc727a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_salt_1 = df_balanced_salt.withColumn(\"explodCol\",  F.explode(df_balanced_salt.salt_array) ).drop(\"salt_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "309b22fc-9574-4f46-96a3-a00f1a13df72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:01:04 WARN scheduler.TaskSetManager: Stage 48 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_salt_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38231ce3-85dc-44ed-9d3a-2d3fe5f96eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:01:05 WARN scheduler.TaskSetManager: Stage 50 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+\n",
      "| value|partitionId|explodCol|\n",
      "+------+-----------+---------+\n",
      "|600064|          3|        0|\n",
      "|600064|          3|        1|\n",
      "|600064|          3|        2|\n",
      "|600065|          3|        0|\n",
      "|600065|          3|        1|\n",
      "+------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_balanced_salt_1.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0bb00a8-a5c0-46a2-a0ba-9b4b853bd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_salt_2 = df_balanced_salt_1.withColumn(\"salt\", F.concat(df_balanced_salt_1.value,  F.lit(\"_\"), df_balanced_salt_1.explodCol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdbcc4a6-00f5-4e68-a4f8-e4353e04aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:01:06 WARN scheduler.TaskSetManager: Stage 52 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------+--------+\n",
      "| value|partitionId|explodCol|    salt|\n",
      "+------+-----------+---------+--------+\n",
      "|799744|          4|        0|799744_0|\n",
      "|799744|          4|        1|799744_1|\n",
      "|799744|          4|        2|799744_2|\n",
      "|799745|          4|        0|799745_0|\n",
      "|799745|          4|        1|799745_1|\n",
      "+------+-----------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_balanced_salt_2.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5eec4-972d-41c0-8daa-f3b689222721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "530c6be9-eb6e-4885-957b-5b98732b79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salt = df_skew_salt.join(df_balanced_salt_2, [\"salt\"], \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78606b43-fccb-4a8e-9aea-7495f9c7c694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:01:06 WARN scheduler.TaskSetManager: Stage 57 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/03/26 11:01:12 WARN scheduler.TaskSetManager: Lost task 1.1 in stage 59.0 (TID 826) (datanode1 executor 5): TaskKilled (another attempt succeeded)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ac72570-ce55-4f44-9189-7e2e73d547f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+-----+-----------+---------+\n",
      "|salt|value|partitionId|value|partitionId|explodCol|\n",
      "+----+-----+-----------+-----+-----------+---------+\n",
      "| 2_2|    2|          2|    2|          0|        2|\n",
      "| 0_0|    0|          0|    0|          0|        0|\n",
      "| 0_0|    0|          0|    0|          0|        0|\n",
      "| 0_0|    0|          0|    0|          0|        0|\n",
      "| 0_0|    0|          0|    0|          0|        0|\n",
      "+----+-----+-----------+-----+-----------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/26 11:16:11 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_213_0 !\n",
      "23/03/26 11:16:11 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_213_1 !\n",
      "23/03/26 11:16:12 ERROR cluster.YarnScheduler: Lost executor 1 on datanode4: Container from a bad node: container_1679827331130_0002_01_000002 on host: datanode4. Exit status: 137. Diagnostics: [2023-03-26 11:16:11.815]Container killed on request. Exit code is 137[2023-03-26 11:16:11.819]\n",
      "[2023-03-26 11:16:11.822]Container exited with a non-zero exit code 137. [2023-03-26 11:16:11.822]\n",
      "[2023-03-26 11:16:11.823]Killed by external signal\n",
      ".\n",
      "23/03/26 11:16:12 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container from a bad node: container_1679827331130_0002_01_000002 on host: datanode4. Exit status: 137. Diagnostics: [2023-03-26 11:16:11.815]Container killed on request. Exit code is 137[2023-03-26 11:16:11.819]\n",
      "[2023-03-26 11:16:11.822]Container exited with a non-zero exit code 137. [2023-03-26 11:16:11.822]\n",
      "[2023-03-26 11:16:11.823]Killed by external signal\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "df_salt.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f0499-002d-4ba5-b312-821b5ed16244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63d824-cc3f-42f6-8a39-1e0304cdde07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3db559-1d64-48ae-b43d-ab9c6a7be61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d06ab0-6e70-4694-8cfa-2a654f2803bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68331ff-f7ac-436d-9b24-d5fec16a46b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5812ca-99e6-45b7-9e85-045d6317b860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94cb5832-69c9-4500-8a8a-e0925d347595",
   "metadata": {},
   "source": [
    "#### 4. AQE (Spark 3x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc1f9b-d3e1-4abd-a2c8-fe5726518cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1fe4d6-102a-49ac-8a12-f6d139716699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 3",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
